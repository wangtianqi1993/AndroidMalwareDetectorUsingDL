# !/usr/bin/env python
# -*- coding: utf-8 -*-
__author__ = 'wtq'

import os
import csv
import tensorflow as tf
import numpy as np
from detector.malware.train.feature import ExtractFeature

dir_path = os.path.dirname(__file__)
input_data_path = os.path.abspath(os.path.join(dir_path, "data", "apk_classification_data.txt"))


feature = ExtractFeature()


class AutoEncoder(object):
    """
    using multi-layer forward neural network to abstract and extract feature
    """

    def __init__(self):
        self.n_hidden_1 = 78
        self.n_hidden_2 = 60
        self.n_input = 98
        self.weights = {
            "encoder_h1": tf.Variable(tf.random_normal([self.n_input, self.n_hidden_1])),
            "encoder_h2": tf.Variable(tf.random_normal([self.n_hidden_1, self.n_hidden_2])),
            "decoder_h1": tf.Variable(tf.random_normal([self.n_hidden_2, self.n_hidden_1])),
            "decoder_h2": tf.Variable(tf.random_normal([self.n_hidden_1, self.n_input])),
        }
        self.biases = {
            "encoder_b1": tf.Variable(tf.random_normal([self.n_hidden_1])),
            "encoder_b2": tf.Variable(tf.random_normal([self.n_hidden_2])),
            "decoder_b1": tf.Variable(tf.random_normal([self.n_hidden_1])),
            "decoder_b2": tf.Variable(tf.random_normal([self.n_input])),
        }

    def encoder(self, x):
        layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights["encoder_h1"]), self.biases["encoder_b1"]))
        layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights["encoder_h2"]), self.biases["encoder_b2"]))
        return layer_2

    def decoder(self, x):
        layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights["decoder_h1"]), self.biases["decoder_b1"]))
        layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights["decoder_h2"]), self.biases["decoder_b2"]))
        return layer_2

    def train_parameter(self, train_data, learning_rate=0.01, training_epochs=50, batch_size=100):
        """

        :param train_data:
        :param learning_rate:
        :param training_epochs: training the full sample's time
        :param batch_size: size for each training
        :return:
        """
        input_data = tf.placeholder("float", [None, self.n_input])
        encoder_data = self.encoder(input_data)
        decoder_data = self.decoder(encoder_data)

        cost = tf.reduce_mean(tf.pow(input_data - decoder_data, 2))
        optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)

        init = tf.initialize_all_variables()
        with tf.Session() as sess:
            sess.run(init)
            total_batch = int(len(train_data) / batch_size)

            for epoch in range(training_epochs):
                for i in range(total_batch):
                    # get batch size data of the whole data
                    batch_data = train_data[i * batch_size:(i + 1) * batch_size]
                    op, c = sess.run([optimizer, cost], feed_dict={input_data: batch_data})

                print("Epoch:", '%04d' % (epoch + 1),
                      "cost=", "{:.9f}".format(c))
            print("Optimization Finished")

            # return the encoder data
            encode_data = sess.run(encoder_data, feed_dict={input_data: train_data})

            return encode_data

    def write_encoder_feature_to_file(self, file_path):
        """

        :param file_path:
        :return:
        """
        train, test, all = feature.generate_vector()
        feature_vector = []
        final_vector = []
        for item in all:
            feature_vector.append(map(float, item))
        encoder_feature = self.train_parameter(feature_vector)

        with open(file_path, 'wb') as f:
            writer = csv.writer(f)
            for index in range(0, len(encoder_feature)):
                # 从tensorflow中输出的是np.array()类型，使用tolist()来转换为list类型
                item = encoder_feature[index].tolist()
                if index < 1360:
                    item.extend([1.0, 0.0])
                    writer.writerow(item)
                    # add the feature label
                else:
                    item.extend([0.0, 1.0])
                    writer.writerow(item)

if __name__ == "__main__":
    auto_encoder = AutoEncoder()
    # auto_encoder.write_encoder_feature_to_file("/home/wtq/encoder_apk_feature.csv")
    # write_test("/home/wtq/testcsv.csv")
