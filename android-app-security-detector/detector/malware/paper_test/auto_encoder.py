# !/usr/bin/env python
# -*- coding: utf-8 -*-
__author__ = 'wtq'

import os
import csv
import tensorflow as tf
import numpy as np
from detector.malware.train.feature import ExtractFeature

feature = ExtractFeature()

dir_path = os.path.dirname(__file__)
input_data_path = os.path.abspath(os.path.join(dir_path, "data", "apk_classification_data.txt"))
encoder_data_path = os.path.abspath(os.path.join(dir_path, "data", "encoder_data.csv"))


class AutoEncoder(object):
    """
    using multi-layer forward neural network to abstract and extract feature
    reducing the data dimension from 98 to 60
    """

    def __init__(self):
        self.n_hidden_1 = 78
        self.n_hidden_2 = 60
        self.n_input = 98
        self.weights = {
            "encoder_h1": tf.Variable(tf.random_normal([self.n_input, self.n_hidden_1])),
            "encoder_h2": tf.Variable(tf.random_normal([self.n_hidden_1, self.n_hidden_2])),
            "decoder_h1": tf.Variable(tf.random_normal([self.n_hidden_2, self.n_hidden_1])),
            "decoder_h2": tf.Variable(tf.random_normal([self.n_hidden_1, self.n_input])),
        }
        self.biases = {
            "encoder_b1": tf.Variable(tf.random_normal([self.n_hidden_1])),
            "encoder_b2": tf.Variable(tf.random_normal([self.n_hidden_2])),
            "decoder_b1": tf.Variable(tf.random_normal([self.n_hidden_1])),
            "decoder_b2": tf.Variable(tf.random_normal([self.n_input])),
        }

    def encoder(self, x):
        layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights["encoder_h1"]), self.biases["encoder_b1"]))
        layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights["encoder_h2"]), self.biases["encoder_b2"]))
        return layer_2

    def decoder(self, x):
        layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, self.weights["decoder_h1"]), self.biases["decoder_b1"]))
        layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, self.weights["decoder_h2"]), self.biases["decoder_b2"]))
        return layer_2

    def train_parameter(self, train_data, learning_rate=0.01, training_epochs=50, batch_size=100):
        """

        :param train_data:
        :param learning_rate:
        :param training_epochs: training the full sample's time
        :param batch_size: size for each training
        :return:
        """
        input_data = tf.placeholder("float", [None, self.n_input])
        encoder_data = self.encoder(input_data)
        decoder_data = self.decoder(encoder_data)

        cost = tf.reduce_mean(tf.pow(input_data - decoder_data, 2))
        optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)

        init = tf.initialize_all_variables()
        with tf.Session() as sess:
            sess.run(init)
            total_batch = int(len(train_data) / batch_size)

            for epoch in range(training_epochs):
                for i in range(total_batch):
                    # get batch size data of the whole data
                    batch_data = train_data[i * batch_size:(i + 1) * batch_size]
                    op, c = sess.run([optimizer, cost], feed_dict={input_data: batch_data})

                print("Epoch:", '%04d' % (epoch + 1),
                      "cost=", "{:.9f}".format(c))
            print("Optimization Finished")

            # return the encoder data
            encode_data = sess.run(encoder_data, feed_dict={input_data: train_data})

            return encode_data

    def read_data(self, input_file_path):
        data = []
        label = []
        class1_count = 0
        class2_count = 0
        with open(input_file_path, "r") as f:
            for line in f:
                tmp_label = []
                tmp_line = map(float, line.split(" "))
                data.append(tmp_line)
                tmp_label.append(tmp_line.pop(-2))
                tmp_label.append(tmp_line.pop())
                if tmp_label[0] > tmp_label[1]:
                    class1_count += 1
                else:
                    class2_count += 1
                if class2_count > 1200:
                    tmp_label = [1, 0]
                label.append(tmp_label)

        print class1_count, class2_count
        return data, label

    def write_encoder_feature_to_file(self, file_path):
        """

        :param file_path:
        :return:
        """
        feature_vector, label_vector = self.read_data(input_data_path)

        encoder_feature = self.train_parameter(feature_vector)
        class1_count = 0
        class2_count = 0

        with open(file_path, 'wb') as f:
            writer = csv.writer(f)
            for index in range(0, len(encoder_feature)):
                # 从tensorflow中输出的是np.array()类型，使用tolist()来转换为list类型
                item = encoder_feature[index].tolist()
                item.extend(label_vector[index])
                if label_vector[index][0] > label_vector[index][1]:
                    class1_count += 1
                else:
                    class2_count += 1
                writer.writerow(item)
        print class1_count, class2_count

if __name__ == "__main__":
    auto_encoder = AutoEncoder()
    auto_encoder.write_encoder_feature_to_file(encoder_data_path)
    # auto_encoder.read_data(input_data_path)
    # write_test("/home/wtq/testcsv.csv")
    # auto_encoder.read_data(input_data_path)
