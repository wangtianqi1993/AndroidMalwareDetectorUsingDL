# !/usr/bin/env python
# -*- coding: utf-8 -*-
__author__ = 'wtq'

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn import metrics
import os

dir_path = os.path.dirname(__file__)
input_data_path = os.path.abspath(os.path.join(dir_path, "data", "encoder_data.csv"))


class PaperTest(object):
    """
    构造贝叶斯，支持向量机，逻辑回归分类算法
    根据参与训练的源数据分为经过autoencoder降维后的数据以及没有降维后的原始数据
    要构造的模型：mod1:使用autoencoder模型降维后的逻辑回归
               mod2:没有使用autoencoder模型降维后的逻辑回归
               mod3:没有使用autoencoder模型降维后的SVM
               mod4:没有使用autoencoder模型降维后的朴素贝叶斯"""

    predictor = None
    train_data = []
    train_data_label = []

    def __init__(self):
        super(PaperTest, self).__init__()

        with open(input_data_path, "r") as f:
            lines = f.readlines()
            for item in lines:
                item_split = map(float, item.split(","))
                label1 = item_split.pop(-2)
                label2 = item_split.pop()
                if label1 >= label2:
                    self.train_data_label.append(0)
                else:
                    self.train_data_label.append(1)
                self.train_data.append(item_split)
        self.predictor.fit(self.train_data, self.train_data_label)

    def test_model(self):
        predict_label = self.predictor.predict(self.train_data)
        print metrics.confusion_matrix(self.train_data_label, predict_label)


class LogistRegressionPredict(PaperTest):
    def __init__(self):
        # 通过class_weight变量设置不同类别的权重比例，
        self.predictor = LogisticRegression(class_weight={0:1, 1:1})
        super(LogistRegressionPredict, self).__init__()


class GaussianNbPredict(PaperTest):
    def __init__(self):
        self.predictor = GaussianNB()
        super(GaussianNbPredict, self).__init__()


class SvmPredict(PaperTest):
    def __init__(self):
        self.predictor = SVC()
        super(SvmPredict, self).__init__()

lr = LogistRegressionPredict()
lr.test_model()

