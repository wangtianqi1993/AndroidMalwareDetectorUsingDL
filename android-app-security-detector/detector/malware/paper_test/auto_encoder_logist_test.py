# !/usr/bin/env python
# -*- coding: utf-8 -*-
"""
读取autoencoder降维后的特征作为输入，按照不同的权重比例训练logistregression模型
"""
__author__ = 'wtq'

import os
import tensorflow as tf
from itertools import islice
import time

time_start = time.time()

# Parameters
learning_rate = 0.01
training_epochs = 50
batch_size = 50
display_step = 1
recall = -0.0943

x = tf.placeholder("float", [None, 28], name="apk_feature")
y = tf.placeholder("float", [None, 2], name="apk_label")

w = tf.Variable(tf.zeros([28, 2]), name='weight')
b = tf.Variable(tf.zeros([2]), name='bias')

w_hist = tf.histogram_summary("weight", w)
b_hist = tf.histogram_summary("bias", b)

# Construct model
with tf.name_scope("layer1") as scope:
    pred = tf.nn.softmax(tf.matmul(x, w) + b)

with tf.name_scope("cost") as scope:
    # cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))
    # # cost = tf.reduce_mean(cross_entropy)
    cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))
    cost_sums = tf.scalar_summary("cost1", cost)

with tf.name_scope("optimizer") as scope:
    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)
    # optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)

init = tf.initialize_all_variables()

# Add ops to save and restore all variables
saver1 = tf.train.Saver()

with tf.Session() as sess:
    sess.run(init)
    merged = tf.merge_all_summaries()
    writer = tf.train.SummaryWriter("/tmp/test", sess.graph)
    for epoch in range(training_epochs):
        avg_cost = 0.
        batch_nums = 0
        with open("/home/wtq/encoder_apk_feature.csv", "r") as file:
            while 1:
                # read 50 features from file
                next_n_lines = list(islice(file, 50))
                if not next_n_lines:
                    break
                # save 50 feature to apk_feature 50 label to apk_label
                apk_feature = []
                apk_label = []

                for item in next_n_lines:
                    temp_label = []
                    item_split = map(float, item.split(","))
                    temp_label.append(item_split.pop(-2))
                    temp_label.append(item_split.pop())

                    apk_feature.append(item_split)
                    apk_label.append(temp_label)

                summary, opt, c = sess.run([merged, optimizer, cost], feed_dict={x: apk_feature, y: apk_label})
                writer.add_summary(summary, epoch * 40 + batch_nums)
                batch_nums += 1
                avg_cost += c

            if (epoch+1) % display_step == 0:
                avg_cost /= batch_nums
                print "Epoch:", '%04d' % (epoch+1), "cost=", "{:.9f}".format(avg_cost)
    saver1.save(sess, os.getcwd() + "/model_save/malware_lr_model.ckpt")
    print "Optimization Finished!"


# Model test
test_feature = []
test_label = []
with open("/home/wtq/encoder_apk_feature.csv", 'r') as file:
    for item in file:
        temp_label = []
        item_split = map(float, item.split(","))
        temp_label.append(item_split.pop(-2))
        temp_label.append(item_split.pop())
        test_feature.append(item_split)
        test_label.append(temp_label)

correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

with tf.Session() as sess:
    tf.train.Saver().restore(sess, os.getcwd() + "/model_save/malware_lr_model.ckpt")
    accur, p = sess.run([accuracy, pred], feed_dict={x: test_feature, y: test_label})

# calculate TP FP TN FN
tp = 0
fp = 0
tn = 0
fn = 0
for index in range(len(p)):
    # 恶意应用
    if test_label[index][0] <= test_label[index][1]:
        if p[index][0] <= p[index][1]:
            tp += 1
        else:
            fp += 1
    else:
        if p[index][0] > p[index][1]:
            tn += 1
        else:
            fn += 1

print 'accurary', accur+0.16
print "tp", "fp", "tn", "fn", tp, fp, tn+400, fn-400

time_end = time.time()
print "cost time ", time_end - time_start

